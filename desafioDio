import zipfile
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
import matplotlib.pyplot as plt
import os
from google.colab import files
from tensorflow.keras.preprocessing import image

dataset_url = "https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip"
data_dir = tf.keras.utils.get_file('cats_and_dogs.zip', origin=dataset_url, extract=True)
data_dir = os.path.join(os.path.dirname(data_dir), 'cats_and_dogs_filtered')

train_dataset = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(160, 160),
  batch_size=32)

validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(160, 160),
  batch_size=32)
  
  pretrained_model = tf.keras.applications.MobileNetV2(input_shape=(160, 160, 3),
                           include_top=False,
                           weights='imagenet')


pretrained_model.trainable = False

model = models.Sequential([
  pretrained_model,
  layers.GlobalAveragePooling2D(),
  layers.Dense(2, activation='softmax') # Para duas classes
])

model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),
       loss='sparse_categorical_crossentropy',
       metrics=['accuracy'])
	   
history = model.fit(train_dataset,
          epochs=10,
          validation_data=validation_dataset)


loss, accuracy = model.evaluate(validation_dataset)
print(f"Accuracy: {accuracy * 100:.2f}%")

plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')
plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')
plt.title('Acurácia do Modelo')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend()
plt.show()


uploaded = files.upload()

# Processa o arquivo ZIP
for fn in uploaded.keys():
    zip_path = fn  # Caminho do arquivo ZIP carregado
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall('/content/temp_images')  # Descompacta na pasta "temp_images"

# Caminho da pasta descompactada
extracted_folder = '/content/temp_images'

# Itera sobre cada imagem descompactada
for img_file in os.listdir(extracted_folder):
    img_path = os.path.join(extracted_folder, img_file)
    
    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Verifica se é uma imagem
        # Carrega e processa a imagem
        img = image.load_img(img_path, target_size=(160, 160))
        img_array = image.img_to_array(img) / 255.0  # Normaliza
        img_array = tf.expand_dims(img_array, axis=0)  # Expande para o batch

        # Faz a previsão com o modelo
        predictions = model.predict(img_array)
        predicted_class = 'Cachorro' if predictions[0][1] > predictions[0][0] else 'Gato'
        
        print(f"A imagem '{img_file}' é um: {predicted_class}")


		
